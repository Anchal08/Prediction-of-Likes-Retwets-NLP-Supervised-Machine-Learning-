{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_after_outlier1 = pd.read_csv(\"C:\\\\Users\\\\ganch\\\\Desktop\\\\Independent Study\\\\python_twitter_collection_sample\\\\binned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(data_after_outlier.bin_class_Retweet)\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(data_after_outlier.bin_class_Likes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsampling Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_1, count_class_2,count_class_3,count_class_4 = data_after_outlier1.bin_class_Retweet.value_counts()\n",
    "\n",
    "# Divide by class\n",
    "df_class_1 = data_after_outlier1[data_after_outlier1['bin_class_Retweet'] == 1]\n",
    "df_class_2 = data_after_outlier1[data_after_outlier1['bin_class_Retweet'] == 2]\n",
    "df_class_3 = data_after_outlier1[data_after_outlier1['bin_class_Retweet'] == 3]\n",
    "df_class_4 = data_after_outlier1[data_after_outlier1['bin_class_Retweet'] == 4]\n",
    "\n",
    "df_class_1_under = df_class_1.sample(count_class_4,replace = True)\n",
    "df_class_2_under = df_class_2.sample(count_class_4,replace = True)\n",
    "df_class_3_under = df_class_3.sample(count_class_4,replace = True)\n",
    "df_class_4_under = df_class_4.sample(count_class_4,replace = True)\n",
    "df_test_under = pd.concat([df_class_1_under, df_class_2_under,df_class_3_under,df_class_4_under], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(df_test_under.bin_class_Retweet.value_counts())\n",
    "\n",
    "df_test_under.bin_class_Retweet.value_counts().plot(kind='bar', title='Count (bin_class_Retweet)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsampling Likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_1, count_class_2,count_class_3,count_class_4 = data_after_outlier1.bin_class_Likes.value_counts()\n",
    "\n",
    "# Divide by class\n",
    "df_class_1 = data_after_outlier1[data_after_outlier1['bin_class_Likes'] == 1]\n",
    "df_class_2 = data_after_outlier1[data_after_outlier1['bin_class_Likes'] == 2]\n",
    "df_class_3 = data_after_outlier1[data_after_outlier1['bin_class_Likes'] == 3]\n",
    "df_class_4 = data_after_outlier1[data_after_outlier1['bin_class_Likes'] == 4]\n",
    "\n",
    "df_class_1_under = df_class_1.sample(count_class_4,replace = True)\n",
    "df_class_2_under = df_class_2.sample(count_class_4,replace = True)\n",
    "df_class_3_under = df_class_3.sample(count_class_4,replace = True)\n",
    "df_class_4_under = df_class_4.sample(count_class_4,replace = True)\n",
    "df_test_under_Likes = pd.concat([df_class_1_under, df_class_2_under,df_class_3_under,df_class_4_under], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(df_test_under_Likes.bin_class_Likes.value_counts())\n",
    "\n",
    "df_test_under_Likes.bin_class_Likes.value_counts().plot(kind='bar', title='Count (bin_class_Likes)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df_test_under_Likes[[\"clean_text\"]]\n",
    "y = df_test_under_Likes['bin_class_Likes']\n",
    "#y = df_test_under_Likes['bin_class_Retweet']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline,param_grid = {'clf__solver': ('newton-cg', 'lbfgs', 'liblinear', 'saga')}, cv=5,\n",
    "                               n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "#if type() is str:\n",
    "#       tweet = tweet.lower()\n",
    "grid_search.fit(list(X_train.clean_text), list(y_train))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "y_true, y_pred = y_test, grid_search.predict(list(X_test.clean_text))\n",
    "accuracy_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SVC())\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline,param_grid = {'clf__kernel':['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'clf__degree':[1, 2, 3, 4],\n",
    "            'clf__C':[0.5, 1, 2]}, cv=5,\n",
    "                               n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "\n",
    "grid_search.fit(list(X_train.clean_text), list(y_train))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "y_true, y_pred = y_test, grid_search.predict(list(X_test.clean_text))\n",
    "accuracy_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline,param_grid = {'clf__alpha': [0, 0.5, 1],\n",
    "                'clf__fit_prior': [True, False]}, cv=5,\n",
    "                               n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "\n",
    "grid_search.fit(list(X_train.clean_text), list(y_train))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "y_true, y_pred = y_test, grid_search.predict(list(X_test.clean_text))\n",
    "accuracy_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf'a, RandomForestClassifier())\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline,param_grid = {'clf__max_features': [None],\n",
    "                'clf__n_estimators': [100],'clf__min_samples_leaf' : [5]}, cv=5,\n",
    "                               n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "\n",
    "grid_search.fit(list(X_train.clean_text), list(y_train))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "y_true, y_pred = y_test, grid_search.predict(list(X_test.clean_text))\n",
    "accuracy_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "a = df_test_under['bin_class_Retweet']\n",
    "label_binarizer = sklearn.preprocessing.LabelBinarizer()\n",
    "label_binarizer.fit(range(max(a)+1))\n",
    "b = label_binarizer.transform(a)\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X = df_test_under[\"clean_text\"].values\n",
    "vectorizer = TfidfVectorizer(\n",
    "                             use_idf = True,\n",
    "                            stop_words='english',\n",
    "                            max_features=25000)\n",
    "X = vectorizer.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, b, test_size=0.30, random_state=42)\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(512 ,input_dim=25000, activation='relu'))\n",
    "model1.add(Dense(256, activation='sigmoid'))\n",
    "model1.add(Dropout(0.3))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "model1.add(Dropout(0.3))\n",
    "model1.add(Dense(5, activation='softmax'))\n",
    "# Compile model\n",
    "\n",
    "#use for narratives\n",
    "sgd=optimizers.Adamax(decay=0.01)\n",
    "##use for issues\n",
    "# sgd=optimizers.SGD(lr=0.01, decay=0.001)\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "history=model1.fit(X_train, y_train,batch_size=512, epochs=100, validation_data=(X_test, y_test), verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
